{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"h3Wsitw7fCqM"},"outputs":[],"source":["import numpy as np\n","import torch\n","import torch.nn as nn\n","from IPython.display import Audio\n","\n","import os\n","from sklearn.model_selection import train_test_split\n","import random\n","from random import randint\n","from torch.utils.data import DataLoader, TensorDataset\n","import matplotlib.pyplot as plt\n","import gc\n","from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QI2awCm5fCqO"},"outputs":[],"source":["sampling_rate = 8_000\n","languages = [\"de\", \"en\", \"es\", \"fr\", \"nl\", \"pt\"]\n","language_dict = {languages[i]: i for i in range(len(languages))}\n","\n","X_train, y_train = np.load(\"dataset/inputs_train_fp16.npy\"), np.load(\n","    \"dataset/targets_train_int8.npy\")\n","\n","X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.2, stratify = y_train)\n","\n","X_test, y_test = np.load(\"dataset/inputs_test_fp16.npy\"), np.load(\n","    \"dataset/targets_test_int8.npy\")\n","\n","X_train, X_val, X_test = X_train.astype(np.float32), X_val.astype(np.float32), X_test.astype(np.float32)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"skCnNdeX9oHG"},"outputs":[],"source":["#Change all labels to one hot encoding\n","targets_full = torch.from_numpy(y_train)\n","y_train = torch.nn.functional.one_hot(targets_full.long(), 6).float()\n","\n","targets_full = torch.from_numpy(y_val)\n","y_val = torch.nn.functional.one_hot(targets_full.long(), 6).float()\n","\n","targets_full = torch.from_numpy(y_test)\n","y_test = torch.nn.functional.one_hot(targets_full.long(), 6).float()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wWQotNeZfCqR"},"outputs":[],"source":["#https://librosa.org/doc/main/generated/librosa.feature.melspectrogram.html\n","#https://dsp.stackexchange.com/questions/75017/generating-log-mel-spectrogram-using-librosa\n","#https://importchris.medium.com/how-to-create-understand-mel-spectrograms-ff7634991056\n","#Creation of the mel spectogram normalization, first used to be log mel spectogram but it didn't perform well, so we changed to to mel spectogram\n","import librosa\n","\n","class Gspectogram(torch.nn.Module):\n","    def __init__(self, sample_rate=8000, n_fft=2048, hop_length=256, n_mels=32): #parameters were slightly adjusted but didnt show alot of difference\n","\n","        super(Gspectogram, self).__init__()\n","\n","        self.sample_rate = sample_rate\n","        self.n_fft = n_fft\n","        self.hop_length = hop_length\n","        self.n_mels = n_mels\n","\n","    def forward(self, audio):\n","        batch_size = audio.size(0)\n","        num_samples = audio.size(-1)\n","\n","        mel_spectrogram = []\n","        for i in range(batch_size):\n","            mel = librosa.feature.melspectrogram(\n","                y=audio[i].detach().cpu().numpy(),\n","                sr=self.sample_rate,\n","                n_fft=self.n_fft,\n","                hop_length=self.hop_length,\n","                n_mels=self.n_mels\n","            )\n","            mel_spectrogram.append(mel)\n","        \n","        mel_spectrogram = torch.tensor(mel_spectrogram).to(audio.device)\n","\n","        return mel_spectrogram"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Nr7MDpkXEGsn"},"outputs":[],"source":["#https://bioacoustics.stackexchange.com/questions/846/should-we-normalize-audio-before-training-a-ml-model\n","# Mean variance normalizer to normalize the data before sending it to the spectogram normalizer\n","class MVNormalizer(torch.nn.Module):\n","    def __init__(self, num_features=40000, eps=1e-6):\n","        super(MVNormalizer, self).__init__()\n","        self.num_features = num_features\n","        self.eps = eps\n","        \n","        self.mean = torch.nn.Parameter(torch.zeros(num_features), requires_grad=False)\n","        self.var = torch.nn.Parameter(torch.ones(num_features), requires_grad=False)\n","      \n","    def forward(self, x):\n","        if self.training:\n","            mean = x.mean(dim=0)\n","            var = x.var(dim=0, unbiased=False)\n","            self.mean.data = 0.99 * self.mean.data + 0.01 * mean\n","            self.var.data = 0.99 * self.var.data + 0.01 * var\n","        return (x - self.mean) / torch.sqrt(self.var + self.eps) \n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3UxmPIMcB8wH"},"outputs":[],"source":["X_trainset = torch.utils.data.TensorDataset(torch.from_numpy(X_train), y_train)\n","X_valset = torch.utils.data.TensorDataset(torch.from_numpy(X_val), y_val)\n","X_testset = torch.utils.data.TensorDataset(torch.from_numpy(X_test), y_test)\n","\n","dataloader_train = torch.utils.data.DataLoader(X_trainset, batch_size=64, shuffle=True, drop_last=True)\n","dataloader_val = torch.utils.data.DataLoader(X_valset, batch_size=64, shuffle=False, drop_last=True)\n","dataloader_test = torch.utils.data.DataLoader(X_testset, batch_size=64, shuffle=False, drop_last=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xY2-xWF0pJBT"},"outputs":[],"source":["class CustomLC(nn.Module):\n","  def __init__(self, num_classes=6):\n","    super(CustomLC, self).__init__()\n","\n","    self.norm = MVNormalizer() # tried both with and without both normalizer, the best accuracy was given when both were used \n","    self.norm1 = Gspectogram()\n","\n","    self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, stride=1, padding=1) # all layers used to be 1d for conv and pool, but since we used both normalizers we had to chnage it to 3d\n","    self.relu1 = nn.LeakyReLU() # use leaky relu instead of ReLU since we have negative values in input data\n","    self.pool1 = nn.MaxPool2d(kernel_size=2)\n","\n","    self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n","    self.relu2 = nn.LeakyReLU()\n","    self.pool2 = nn.MaxPool2d(kernel_size=2)\n","\n","    self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n","    self.relu3 = nn.LeakyReLU()\n","    self.pool3 = nn.MaxPool2d(kernel_size=2)\n","    \n","    self.flatten = nn.Flatten()\n","    self.fc1 = nn.Linear(4864, 128)\n","    self.drop1 = nn.Dropout(0.5) # prevent overfitting\n","    self.relu5 = nn.LeakyReLU()\n","    self.fc2 = nn.Linear(128, num_classes)\n","    self.drop2 = nn.Dropout(0.5) # we needed a second dropout layer since the overfitting would be too much after a few epochs, it would result in the model just guessing 1 langauge\n","    self.softmax = nn.Softmax(dim=1) #seemed to be the best from online sources\n","\n","  def forward(self, x):\n","\n","    x = self.norm(x)\n","    x = self.norm1(x)\n","\n","    x = self.conv1(x)\n","    x = self.relu1(x)\n","    x = self.pool1(x)\n","\n","    x = self.conv2(x)\n","    x = self.relu2(x)\n","    x = self.pool2(x)\n","\n","    x = self.conv3(x)\n","    x = self.relu3(x)\n","    x = self.pool3(x)\n","\n","    x = self.flatten(x)\n","    x = self.fc1(x)\n","    x = self.drop1(x)\n","    x = self.relu5(x)\n","    x = self.fc2(x)\n","    x = self.drop2(x)\n","    x = self.softmax(x)\n","\n","    return x"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HjQa_bxZjdvx"},"outputs":[],"source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qpBccCODuGG3"},"outputs":[],"source":["model = CustomLC()\n","crossloss = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.01) #adding weight_decay to prevent ov\n","model = model.to(device)\n","model.train()\n","\n","loss_list_train = []\n","loss_list_val = []\n","accuracy_list_train = []\n","accuracy_list_val = []\n","\n","for epoch in range(30):\n","  total_loss = 0\n","  total_correct = 0\n","  total_samples = 0\n","  for clips, target in dataloader_train:\n","    clips = clips.view(clips.shape[0], 1, -1)\n","    target = target.to(device).float()\n","    clips = clips.to(device).float()\n","    optimizer.zero_grad()\n","\n","    predictions = model(clips)\n","    loss = crossloss(predictions, target.argmax(dim=1))\n","\n","    loss.backward()\n","    optimizer.step()\n","\n","    total_loss += loss.item() * clips.size(0)\n","    total_correct += torch.eq(predictions.argmax(dim=1), target.argmax(dim=1)).sum().item()\n","    total_samples += clips.size(0)\n","\n","  epoch_loss = total_loss / total_samples\n","  epoch_acc = total_correct / total_samples\n","  print(f\"Epoch {epoch}: loss={epoch_loss:.4f}, accuracy={epoch_acc:.4f}\")\n","  loss_list_train.append(round(epoch_loss, 4))\n","  accuracy_list_train.append(round(epoch_acc, 4))\n","\n","  with torch.no_grad():\n","    total_loss = 0\n","    total_correct = 0\n","    total_samples = 0\n","    for clips, target in dataloader_val:\n","      clips = clips.view(clips.shape[0], 1, -1)\n","      target = target.to(device).float()\n","      clips = clips.to(device).float()\n","\n","      predictions = model(clips)\n","      loss = crossloss(predictions, target.argmax(dim=1))\n","\n","      total_loss += loss.item() * clips.size(0)\n","      total_correct += torch.eq(predictions.argmax(dim=1), target.argmax(dim=1)).sum().item()\n","      total_samples += clips.size(0)\n","\n","    epoch_loss = total_loss / total_samples\n","    epoch_acc = total_correct / total_samples\n","    print(f\"Epoch {epoch}: loss={epoch_loss:.4f}, accuracy={epoch_acc:.4f}\")\n","    loss_list_val.append(round(epoch_loss, 4))\n","    accuracy_list_val.append(round(epoch_acc, 4))\n","\n","    if epoch > 15:\n","      torch.save(model.state_dict(), f\"model_epoch_{epoch}.pth\")\n","\n","    gc.collect()\n","    torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WTEog5EDwuyJ"},"outputs":[],"source":["model.load_state_dict(torch.load(\"model_final.pth\"))\n","\n","confusion_matrix_test = None\n","\n","with torch.no_grad():\n","  model.eval()\n","  total_loss = 0\n","  total_correct = 0\n","  total_samples = 0\n","  all_targets = []\n","  all_predictions = []\n","  all_targets1 = []\n","  all_predictions1 = []\n","  for clips, target in dataloader_test:\n","    clips = clips.view(clips.shape[0], 1, -1)\n","    target = target.to(device).float()\n","    clips = clips.to(device).float()\n","\n","    predictions = model(clips)\n","    loss = crossloss(predictions, target.argmax(dim=1))\n","\n","    total_loss += loss.item() * clips.size(0)\n","    total_correct += torch.eq(predictions.argmax(dim=1), target.argmax(dim=1)).sum().item()\n","    total_samples += clips.size(0)\n","    all_targets.append(target.argmax(dim=1).cpu())\n","    all_predictions.append(predictions.argmax(dim=1).cpu())\n","    all_predictions1.append(predictions.cpu())\n","    all_targets1.append(target.cpu())\n","\n","  epoch_loss = total_loss / total_samples\n","  epoch_acc = total_correct / total_samples\n","  print(f\"Epoch {epoch}: loss={epoch_loss:.4f}, accuracy={epoch_acc:.4f}\")\n","  all_targets = np.concatenate(all_targets)\n","  all_predictions = np.concatenate(all_predictions)\n","  confusion_matrix_test = confusion_matrix(all_targets, all_predictions)\n","  print(classification_report(all_targets, all_predictions, target_names=[\"German\", \"English\", \"Spanish\", \"French\", \"Dutch\", \"Portuguese\"]))\n","  disp = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix_test,display_labels=[\"German\", \"English\", \"Spanish\", \"French\", \"Dutch\", \"Portuguese\"])\n","  disp.plot()\n","  plt.show()"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"ml","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"}},"nbformat":4,"nbformat_minor":0}